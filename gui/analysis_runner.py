"""
åˆ†ææ‰§è¡Œæ¨¡å— - å¤„ç†åˆ†ææµç¨‹çš„æ‰§è¡Œé€»è¾‘
"""
import streamlit as st
import time
from typing import List, Dict, Any
from error_handler import with_error_handling, print_exception_details
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG
from config_utils import get_provider_info
from gui_utils import save_analysis_results
from gui.state_manager import state_manager


class AnalysisRunner:
    """åˆ†ææ‰§è¡Œå™¨ - å¤„ç†åˆ†ææµç¨‹çš„æ ¸å¿ƒé€»è¾‘"""
    
    def __init__(self):
        self.graph = None
        self.init_state = None
        self.args = None
    
    @with_error_handling
    def run_analysis(self, ticker: str, analysis_date: str, selected_analysts: List[str], 
                    research_depth: int, llm_provider: str, deep_model: str, quick_model: str) -> bool:
        """æ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
        try:
            # åˆå§‹åŒ–åˆ†æç¯å¢ƒ
            if not self._initialize_analysis(ticker, analysis_date, selected_analysts, 
                                           research_depth, llm_provider, deep_model, quick_model):
                return False
            
            # æ‰§è¡Œåˆ†ææµç¨‹
            success = self._execute_analysis_stream()
            
            if success and not st.session_state.stop_analysis:
                # å®Œæˆåˆ†æ
                self._finalize_analysis()
                return True
            else:
                self._handle_analysis_stopped()
                return False
                
        except Exception as e:
            self._handle_analysis_error(e)
            return False
        finally:
            self._cleanup_analysis()
    
    def _initialize_analysis(self, ticker: str, analysis_date: str, selected_analysts: List[str], 
                           research_depth: int, llm_provider: str, deep_model: str, quick_model: str) -> bool:
        """åˆå§‹åŒ–åˆ†æç¯å¢ƒ"""
        # è®¾ç½®åˆ†æå‚æ•°
        state_manager.set_analysis_params(ticker, analysis_date)
        
        # æ¸…ç©ºä¹‹å‰çš„æ—¥å¿—å’ŒçŠ¶æ€
        state_manager.clear_api_logs()
        state_manager.add_api_log_with_container_update("info", f"å¼€å§‹åˆ†æ {ticker.upper()} ({analysis_date})")
        
        # é‡ç½®çŠ¶æ€ - ä½¿ç”¨state_managerç»Ÿä¸€ç®¡ç†
        state_manager.set_stop_analysis(False)
        state_manager.set_analysis_progress(0.0)
        # ä¸åœ¨æ­¤é‡ç½® analysis_startingï¼Œä¿æŒæŒ‰é’®çŠ¶æ€æ­£ç¡®
        
        # åˆ›å»ºè¿›åº¦æ˜¾ç¤º
        progress_placeholder = st.empty()
        
        try:
            with progress_placeholder.container():
                st.info("ğŸš€ æ­£åœ¨åˆå§‹åŒ–åˆ†æç³»ç»Ÿ...")
                init_progress = st.progress(0.0)
                init_status = st.empty()
            
            # æ­¥éª¤1: è§£æåˆ†æå¸ˆé…ç½®
            analyst_types = self._parse_analyst_selection(selected_analysts)
            init_status.text("ğŸ“‹ è§£æåˆ†æå¸ˆé…ç½®...")
            init_progress.progress(0.1)
            state_manager.add_api_log_with_container_update("info", f"é…ç½®åˆ†æå¸ˆ: {', '.join(analyst_types)}")
            
            # æ­¥éª¤2: åˆ›å»ºé…ç½®
            config = self._create_analysis_config(research_depth, llm_provider, deep_model, quick_model)
            init_status.text("âš™ï¸ é…ç½®LLMæä¾›å•†...")
            init_progress.progress(0.2)
            state_manager.add_api_log_with_container_update("info", f"LLMæä¾›å•†: {llm_provider}, æ·±åº¦æ¨¡å‹: {deep_model}, å¿«é€Ÿæ¨¡å‹: {quick_model}")
            
            # æ­¥éª¤3: åˆå§‹åŒ–å›¾
            if not self._initialize_trading_graph(analyst_types, config):
                return False
            init_status.text("ğŸ¤– åˆå§‹åŒ–TradingAgentså›¾...")
            init_progress.progress(0.5)
            
            # æ­¥éª¤4: åˆ›å»ºåˆå§‹çŠ¶æ€
            if not self._create_initial_state(ticker, analysis_date):
                return False
            init_status.text("ğŸ“Š åˆ›å»ºåˆå§‹åˆ†æçŠ¶æ€...")
            init_progress.progress(0.8)
            
            init_status.text("âœ… åˆå§‹åŒ–å®Œæˆï¼Œå¼€å§‹åˆ†æ...")
            init_progress.progress(1.0)
            time.sleep(0.5)
            
            # åˆå§‹åŒ–å®Œæˆåï¼Œä» starting çŠ¶æ€è½¬æ¢åˆ° running çŠ¶æ€
            state_manager.transition_to_running()
            
            # æ¸…ç©ºåˆå§‹åŒ–æ˜¾ç¤º
            progress_placeholder.empty()
            return True
            
        except Exception as e:
            progress_placeholder.empty()
            # å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨state_manageré‡ç½®çŠ¶æ€
            state_manager.set_analysis_starting(False)
            state_manager.set_analysis_running(False)
            raise e
    
    def _parse_analyst_selection(self, selected_analysts: List[str]) -> List[str]:
        """è§£æåˆ†æå¸ˆé€‰æ‹©"""
        analyst_types = []
        for choice in selected_analysts:
            analyst_type = choice.split(" - ")[0]
            analyst_types.append(analyst_type)
        return analyst_types
    
    def _create_analysis_config(self, research_depth: int, llm_provider: str, 
                              deep_model: str, quick_model: str) -> Dict[str, Any]:
        """åˆ›å»ºåˆ†æé…ç½®"""
        config = DEFAULT_CONFIG.copy()
        config["max_debate_rounds"] = research_depth
        config["max_risk_discuss_rounds"] = research_depth
        config["deep_think_llm"] = deep_model
        config["quick_think_llm"] = quick_model
        config["llm_provider"] = llm_provider.lower()
        
        # è·å–æä¾›å•†ä¿¡æ¯
        provider_info = get_provider_info(llm_provider)
        if provider_info:
            config["backend_url"] = provider_info["api_base_url"]
            config["api_key"] = provider_info["api_key"]
            state_manager.add_api_log("api_call", f"è¿æ¥åˆ°API: {provider_info['api_base_url']}")
        else:
            raise Exception(f"æœªæ‰¾åˆ°æä¾›å•†é…ç½®: {llm_provider}")
        
        config["online_tools"] = True
        return config
    
    def _initialize_trading_graph(self, analyst_types: List[str], config: Dict[str, Any]) -> bool:
        """åˆå§‹åŒ–TradingAgentså›¾"""
        try:
            print(f"[DEBUG] å¼€å§‹åˆå§‹åŒ–TradingAgentsGraph...")
            print(f"[DEBUG] åˆ†æå¸ˆç±»å‹: {analyst_types}")
            print(f"[DEBUG] é…ç½®å‚æ•°: {config}")
            
            self.graph = TradingAgentsGraph(
                selected_analysts=analyst_types,
                config=config,
                debug=True
            )
            
            print(f"[DEBUG] TradingAgentsGraphåˆå§‹åŒ–æˆåŠŸ")
            state_manager.add_api_log_with_container_update("response", "äº¤æ˜“ä»£ç†ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"[DEBUG] TradingAgentsGraphåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            print(f"[DEBUG] é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            state_manager.add_api_log_with_container_update("error", f"åˆå§‹åŒ–TradingAgentsGraphå¤±è´¥: {str(e)}")
            raise e
    
    def _create_initial_state(self, ticker: str, analysis_date: str) -> bool:
        """åˆ›å»ºåˆå§‹åˆ†æçŠ¶æ€"""
        try:
            print(f"[DEBUG] å¼€å§‹åˆ›å»ºåˆå§‹çŠ¶æ€...")
            print(f"[DEBUG] è‚¡ç¥¨ä»£ç : {ticker}, åˆ†ææ—¥æœŸ: {analysis_date}")
            
            self.init_state = self.graph.propagator.create_initial_state(ticker, analysis_date)
            self.args = self.graph.propagator.get_graph_args()
            
            print(f"[DEBUG] åˆå§‹çŠ¶æ€åˆ›å»ºæˆåŠŸ")
            print(f"[DEBUG] åˆå§‹çŠ¶æ€å†…å®¹: {list(self.init_state.keys()) if hasattr(self.init_state, 'keys') else type(self.init_state)}")
            print(f"[DEBUG] å›¾å‚æ•°: {self.args}")
            state_manager.add_api_log_with_container_update("response", "åˆå§‹åˆ†æçŠ¶æ€åˆ›å»ºæˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"[DEBUG] åˆ›å»ºåˆå§‹çŠ¶æ€å¤±è´¥: {str(e)}")
            print(f"[DEBUG] é”™è¯¯ç±»å‹: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            state_manager.add_api_log_with_container_update("error", f"åˆ›å»ºåˆå§‹çŠ¶æ€å¤±è´¥: {str(e)}")
            raise e
    
    def _execute_analysis_stream(self) -> bool:
        """æ‰§è¡Œåˆ†ææµ"""
        # è®©å³ä¾§çŠ¶æ€ç›‘æ§é¢æ¿å¤„ç†æ‰€æœ‰è¿›åº¦æ˜¾ç¤º
        status_placeholder = st.empty()
        progress_placeholder = st.empty()
        
        step_count = 0
        total_expected_steps = 50
        last_update_time = time.time()
        
        try:
            print(f"[DEBUG] å¼€å§‹æµå¼åˆ†æå¤„ç†...")
            state_manager.add_api_log_with_container_update("info", "å¼€å§‹æµå¼åˆ†æå¤„ç†...")
            
            stream_count = 0
            for chunk in self.graph.graph.stream(self.init_state, **self.args):
                if st.session_state.stop_analysis:
                    print(f"[DEBUG] åˆ†æè¢«ç”¨æˆ·åœæ­¢")
                    state_manager.add_api_log_with_container_update("warning", "åˆ†æè¢«ç”¨æˆ·åœæ­¢")
                    break
                
                stream_count += 1
                step_count += 1
                
                # å¤„ç†æ•°æ®å—
                self._process_stream_chunk(chunk, step_count)
                
                # æ›´æ–°è¿›åº¦ - ä½¿ç”¨state_manager
                progress = min((step_count / total_expected_steps) * 95, 95)
                state_manager.set_analysis_progress(progress)
                
                # æ‰€æœ‰è¿›åº¦ä¿¡æ¯ç”±å³ä¾§çŠ¶æ€ç›‘æ§é¢æ¿å¤„ç†
                current_time = time.time()
                if current_time - last_update_time > 2.0:  # æ¯2ç§’æ›´æ–°ä¸€æ¬¡çŠ¶æ€ï¼Œä½†ä¸æ˜¾ç¤ºUI
                    # çŠ¶æ€æ›´æ–°ç”±å³ä¾§é¢æ¿ç®¡ç†
                    last_update_time = current_time
                
                # é™åˆ¶UIæ›´æ–°é¢‘ç‡
                self._update_ui_if_needed(step_count, last_update_time)
            
            print(f"[DEBUG] æµå¼åˆ†æå®Œæˆï¼Œæ€»å…±å¤„ç† {step_count} æ­¥ï¼Œæµæ•°æ®å—: {stream_count}")
            state_manager.add_api_log("response", f"æµå¼åˆ†æå®Œæˆï¼Œæ€»å…±å¤„ç† {step_count} æ­¥")
            return True
            
        except Exception as e:
            print(f"[DEBUG] åˆ†ææµå¤„ç†å¤±è´¥: {str(e)}")
            state_manager.add_api_log("error", f"åˆ†ææµå¤„ç†å¤±è´¥: {str(e)}")
            raise e
    
    def _process_stream_chunk(self, chunk: Dict[str, Any], step_count: int):
        """å¤„ç†æµæ•°æ®å—"""
        print(f"[DEBUG] æ¥æ”¶åˆ°æµæ•°æ®å— #{step_count}: {list(chunk.keys()) if hasattr(chunk, 'keys') else type(chunk)}")
        
        # æ›´æ–°æŠ¥å‘Šéƒ¨åˆ†
        try:
            self._update_reports_from_chunk(chunk)
        except Exception as e:
            print(f"[DEBUG] æ›´æ–°æŠ¥å‘Šéƒ¨åˆ†å¤±è´¥: {str(e)}")
        
        # æ›´æ–°ä»£ç†çŠ¶æ€
        try:
            self._update_agent_status_from_chunk(chunk)
        except Exception as e:
            print(f"[DEBUG] æ›´æ–°ä»£ç†çŠ¶æ€å¤±è´¥: {str(e)}")
        
        # è®°å½•è¿›åº¦
        if step_count % 10 == 0:
            progress = min((step_count / 50) * 95, 95)
            state_manager.add_api_log("info", f"å¤„ç†æ­¥éª¤ {step_count}, è¿›åº¦ {progress:.1f}%")
    
    def _update_reports_from_chunk(self, chunk: Dict[str, Any]):
        """ä»æ•°æ®å—æ›´æ–°æŠ¥å‘Š"""
        report_mappings = {
            "market_report": "market_report",
            "sentiment_report": "sentiment_report", 
            "news_report": "news_report",
            "fundamentals_report": "fundamentals_report",
            "trader_investment_plan": "trader_investment_plan",
            "final_trade_decision": "final_trade_decision"
        }
        
        for chunk_key, report_key in report_mappings.items():
            if chunk_key in chunk and chunk[chunk_key]:
                state_manager.update_report_section(report_key, chunk[chunk_key])
        
        # å¤„ç†æŠ•èµ„è¾©è®ºçŠ¶æ€
        if "investment_debate_state" in chunk and chunk["investment_debate_state"]:
            debate_state = chunk["investment_debate_state"]
            if "judge_decision" in debate_state and debate_state["judge_decision"]:
                state_manager.update_report_section("investment_plan", debate_state["judge_decision"])
    
    def _update_agent_status_from_chunk(self, chunk: Dict[str, Any]):
        """ä»æ•°æ®å—æ›´æ–°ä»£ç†çŠ¶æ€"""
        # æ£€æµ‹æ­£åœ¨è¿›è¡Œçš„åˆ†æ
        if "market_analysis" in chunk or any(key.startswith("market") for key in chunk.keys()):
            if not chunk.get("market_report"):
                state_manager.update_agent_status_with_refresh("å¸‚åœºåˆ†æå¸ˆ", "è¿›è¡Œä¸­")
                state_manager.add_api_log_with_container_update("api_call", "å¸‚åœºåˆ†æå¸ˆå¼€å§‹åˆ†æ")
        
        if "sentiment_analysis" in chunk or any(key.startswith("sentiment") for key in chunk.keys()):
            if not chunk.get("sentiment_report"):
                state_manager.update_agent_status_with_refresh("ç¤¾äº¤åˆ†æå¸ˆ", "è¿›è¡Œä¸­")
                state_manager.add_api_log_with_container_update("api_call", "ç¤¾äº¤åˆ†æå¸ˆå¼€å§‹åˆ†æ")
        
        if "news_analysis" in chunk or any(key.startswith("news") for key in chunk.keys()):
            if not chunk.get("news_report"):
                state_manager.update_agent_status_with_refresh("æ–°é—»åˆ†æå¸ˆ", "è¿›è¡Œä¸­")
                state_manager.add_api_log_with_container_update("api_call", "æ–°é—»åˆ†æå¸ˆå¼€å§‹åˆ†æ")
        
        if "fundamentals_analysis" in chunk or any(key.startswith("fundamentals") for key in chunk.keys()):
            if not chunk.get("fundamentals_report"):
                state_manager.update_agent_status_with_refresh("åŸºæœ¬é¢åˆ†æå¸ˆ", "è¿›è¡Œä¸­")
                state_manager.add_api_log_with_container_update("api_call", "åŸºæœ¬é¢åˆ†æå¸ˆå¼€å§‹åˆ†æ")
        
        # æ£€æµ‹å®Œæˆçš„åˆ†æ
        if "market_report" in chunk and chunk["market_report"]:
            state_manager.update_agent_status_with_refresh("å¸‚åœºåˆ†æå¸ˆ", "å·²å®Œæˆ")
            state_manager.add_api_log_with_container_update("response", "å¸‚åœºåˆ†æå®Œæˆ")
        
        if "sentiment_report" in chunk and chunk["sentiment_report"]:
            state_manager.update_agent_status_with_refresh("ç¤¾äº¤åˆ†æå¸ˆ", "å·²å®Œæˆ")
            state_manager.add_api_log_with_container_update("response", "ç¤¾äº¤æƒ…ç»ªåˆ†æå®Œæˆ")
        
        if "news_report" in chunk and chunk["news_report"]:
            state_manager.update_agent_status_with_refresh("æ–°é—»åˆ†æå¸ˆ", "å·²å®Œæˆ")
            state_manager.add_api_log_with_container_update("response", "æ–°é—»åˆ†æå®Œæˆ")
        
        if "fundamentals_report" in chunk and chunk["fundamentals_report"]:
            state_manager.update_agent_status_with_refresh("åŸºæœ¬é¢åˆ†æå¸ˆ", "å·²å®Œæˆ")
            state_manager.add_api_log_with_container_update("response", "åŸºæœ¬é¢åˆ†æå®Œæˆ")
        
        if "investment_debate_state" in chunk and chunk["investment_debate_state"]:
            debate_state = chunk["investment_debate_state"]
            if "judge_decision" in debate_state and debate_state["judge_decision"]:
                state_manager.update_agent_status_with_refresh("ç ”ç©¶ç»ç†", "å·²å®Œæˆ")
                state_manager.add_api_log_with_container_update("response", "ç ”ç©¶å›¢é˜Ÿå†³ç­–å®Œæˆ")
        
        if "trader_investment_plan" in chunk and chunk["trader_investment_plan"]:
            state_manager.update_agent_status_with_refresh("äº¤æ˜“å‘˜", "å·²å®Œæˆ")
            state_manager.add_api_log_with_container_update("response", "äº¤æ˜“è®¡åˆ’åˆ¶å®šå®Œæˆ")
        
        if "final_trade_decision" in chunk and chunk["final_trade_decision"]:
            state_manager.update_agent_status_with_refresh("æŠ•èµ„ç»„åˆç»ç†", "å·²å®Œæˆ")
            state_manager.add_api_log_with_container_update("response", "æœ€ç»ˆäº¤æ˜“å†³ç­–å®Œæˆ")
    
    def _update_ui_if_needed(self, step_count: int, last_update_time: float):
        """åœ¨éœ€è¦æ—¶æ›´æ–°UI"""
        current_time = time.time()
        if current_time - last_update_time > 1.0:
            print(f"[DEBUG] æ›´æ–°UIçŠ¶æ€ä¿¡æ¯...")
            info = f"æ­¥éª¤ {step_count} | {st.session_state.current_status}"
            state_manager.set_last_step_info(info)
            
            # ç§»é™¤st.rerun()è°ƒç”¨ï¼Œé¿å…ä¸­æ–­åˆ†ææµç¨‹
            # çŠ¶æ€æ›´æ–°ä¼šé€šè¿‡session_stateè‡ªç„¶åæ˜ åˆ°UIä¸Š
    
    def _finalize_analysis(self):
        """å®Œæˆåˆ†æ"""
        # ä½¿ç”¨state_managerå®Œæˆåˆ†æ
        state_manager.finalize_analysis_success()
        
        # ä½¿ç”¨å®¹å™¨æ˜¾ç¤ºå®ŒæˆçŠ¶æ€ï¼Œé¿å…st.rerun()
        completion_placeholder = st.empty()
        with completion_placeholder.container():
            st.progress(1.0)
            st.success("ğŸ‰ åˆ†ææˆåŠŸå®Œæˆï¼")
        
        # ä¿å­˜åˆ†æç»“æœ
        self._save_analysis_results()
    
    def _save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            saved_path = save_analysis_results(
                results=st.session_state.report_sections,
                ticker=st.session_state.current_ticker,
                analysis_date=st.session_state.current_date
            )
            
            # ä½¿ç”¨å®¹å™¨æ˜¾ç¤ºä¿å­˜ç»“æœ
            results_placeholder = st.empty()
            with results_placeholder.container():
                st.success(f"ğŸ“ åˆ†æç»“æœå·²ä¿å­˜åˆ°: {saved_path}")
                
                # æ˜¾ç¤ºåˆ†ææ‘˜è¦
                completed_reports = sum(1 for content in st.session_state.report_sections.values() if content)
                total_reports = len(st.session_state.report_sections)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ç”ŸæˆæŠ¥å‘Š", f"{completed_reports}/{total_reports}")
                with col2:
                    total_content = sum(len(str(content)) for content in st.session_state.report_sections.values() if content)
                    st.metric("æ€»å†…å®¹", f"{total_content:,} å­—ç¬¦")
                with col3:
                    st.metric("åˆ†ææ—¶é•¿", "å·²å®Œæˆ")
                    
        except Exception as e:
            error_placeholder = st.empty()
            with error_placeholder.container():
                st.warning(f"âš ï¸ ä¿å­˜åˆ†æç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
    
    def _handle_analysis_stopped(self):
        """å¤„ç†åˆ†æåœæ­¢"""
        stop_placeholder = st.empty()
        with stop_placeholder.container():
            st.warning("â¹ï¸ åˆ†æå·²è¢«ç”¨æˆ·åœæ­¢")
    
    def _handle_analysis_error(self, e: Exception):
        """å¤„ç†åˆ†æé”™è¯¯"""
        # ä½¿ç”¨state_managerå¤„ç†é”™è¯¯çŠ¶æ€
        state_manager.finalize_analysis_failure(str(e))
        
        # ä½¿ç”¨å®¹å™¨æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼Œé¿å…st.rerun()
        error_placeholder = st.empty()
        with error_placeholder.container():
            st.error(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            
            # æä¾›é”™è¯¯è¯¦æƒ…å’Œå»ºè®®
            with st.expander("ğŸ” é”™è¯¯è¯¦æƒ…å’Œè§£å†³å»ºè®®", expanded=True):
                st.text(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                st.text(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
                
                # åœ¨æ§åˆ¶å°æ˜¾ç¤ºå®Œæ•´å †æ ˆè·Ÿè¸ª
                print_exception_details(e, "Streamlitåˆ†æè¿‡ç¨‹")
                
                st.markdown("**å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:**")
                st.markdown("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
                st.markdown("2. éªŒè¯LLM APIå¯†é’¥é…ç½®")
                st.markdown("3. ç¡®è®¤`llm_provider.json`æ–‡ä»¶æ ¼å¼æ­£ç¡®")
                st.markdown("4. æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æœ‰æ•ˆ")
                st.markdown("5. å°è¯•ä½¿ç”¨è¾ƒå°‘çš„åˆ†æå¸ˆæˆ–è¾ƒä½çš„ç ”ç©¶æ·±åº¦")
                st.markdown("6. æŸ¥çœ‹ç»ˆç«¯æ§åˆ¶å°è·å–å®Œæ•´é”™è¯¯å †æ ˆä¿¡æ¯")
    
    def _cleanup_analysis(self):
        """æ¸…ç†åˆ†æèµ„æº"""
        print(f"[DEBUG] åˆ†æçº¿ç¨‹çš„finallyå—å·²æ‰§è¡Œ")
        # ä½¿ç”¨state_manageræ¸…ç†åˆ†æçŠ¶æ€
        state_manager.cleanup_analysis()


# å…¨å±€åˆ†æè¿è¡Œå™¨å®ä¾‹
analysis_runner = AnalysisRunner()